{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(path):\n",
    "   \n",
    "    with open(path, \"r\") as f:\n",
    "        example_tweets = json.load(f)\n",
    "        \n",
    "    return example_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab Invoca's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = load_tweets('tweetDemo.json')\n",
    "print \"Number of tweets downloaded:\", len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets come as a list of nested dictionaries -- a JSON. These are great for giving context to data (metadeta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print tweets[i]['full_text'] + '\\n'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0]['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('tweetDemo.json')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = df.describe()\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['contributors'].isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanThreshhold = 0.5\n",
    "\n",
    "columnstoKeep = [col for col in df.columns if np.mean(df[col].isna()) < nanThreshhold]\n",
    "columnstoKeep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make code predictable, make copies of your dataframe if you're going to work on some subset of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedDf = df.copy().loc[:, columnstoKeep]\n",
    "print truncatedDf.shape\n",
    "\n",
    "truncatedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert truncatedDf['id'].value_counts().mean() == 1\n",
    "assert truncatedDf['id_str'].value_counts().mean() == 1\n",
    "\n",
    "# or, simply,\n",
    "assert truncatedDf['id'].is_unique\n",
    "assert truncatedDf['id_str'].is_unique\n",
    "\n",
    "# if these assert statements get triggered, use df.drop_duplicates() on the primary key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedDf['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use https://pythex.org/ to fiddle with regex pattern\n",
    "\n",
    "Pandas Series string methods: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sourcePattern = r'>(.*)<'\n",
    "\n",
    "cleanedTag = truncatedDf.loc[:, 'source'].str.extract(sourcePattern, expand=False)\n",
    "\n",
    "cleanedTag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary on setting copy warning: https://www.dataquest.io/blog/settingwithcopywarning/\n",
    "As well as the primary documentation at: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "\n",
    "If you're doing any transformation of the dataframe at all,\n",
    "- use loc[row label, column] when setting values\n",
    "- work on copies of your df if you're using a subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'setCopyWarning.png' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont do this: truncatedDf['parsedSource'] = cleanedTag\n",
    "\n",
    "truncatedDf.loc[:, 'parsedSource'] = truncatedDf.loc[:, 'source'].str.extract(sourcePattern, expand=False)\n",
    "\n",
    "truncatedDf = truncatedDf.drop(['source', 'id', 'id_str', 'lang', \n",
    "                                'possibly_sensitive', 'is_quote_status', \n",
    "                                'display_text_range', 'truncated', 'retweeted'], axis = 1)\n",
    "truncatedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedDf['parsedSource'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# benefits of query are only pronounced at > 200k rows\n",
    "truncatedDf.query(\"parsedSource == 'Twitter Web Client' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# this is fine for looking through data or doing calculations\n",
    "truncatedDf[truncatedDf['parsedSource'] == 'Twitter Web Client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# this is the safest way to filter for production\n",
    "truncatedDf.loc[truncatedDf['parsedSource'] == 'Twitter Web Client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "truncatedDf.loc[[src == 'Twitter Web Client' for src in truncatedDf['parsedSource'] ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect there to be 261 True values when we select for iPhone or Android since there is 241 + 20 of these values in the value_counts call above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneOnly = (truncatedDf['parsedSource'] == 'Twitter for iPhone') | (truncatedDf['parsedSource'] == 'Twitter for Android')\n",
    "assert phoneOnly.sum() == 261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = truncatedDf.copy().loc[phoneOnly]\n",
    "phones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = phones.reset_index(drop=True)\n",
    "phones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing data: loc and iloc are only the same when the index is 0, 1, 2, ...\n",
    "\n",
    "Otherwise loc references the given index, while iloc uses the order of entries (always 0, 1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.loc[[1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.iloc[[1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(phones.loc[:, 'created_at'].dt.hour, bins=np.arange(25))\n",
    "plt.xticks(np.arange(25))\n",
    "plt.title('Invoca Tweets from Cell Phones by Hour');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot doesn't make sense -- convert datetime objects to our time zone (Twitter API defaults to UTC -- thanks Google!)\n",
    "\n",
    "For a review of time series methodology in Pandas, see: https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.loc[:, 'created_at'] = phones.loc[:, 'created_at'].astype('datetime64[ns]') \n",
    "\n",
    "phones.loc[:, 'correctedTime'] = (\n",
    "                                    phones.loc[:, 'created_at'].dt.tz_localize('UTC')\n",
    "                                                               .dt.tz_convert('PST8PDT')\n",
    "                                 )\n",
    "\n",
    "phones.loc[:, 'hour'] = phones.loc[:, 'correctedTime'].dt.hour\n",
    "phones.loc[:, 'month'] = phones.loc[:, 'correctedTime'].dt.month\n",
    "phones.loc[:, 'day'] = phones.loc[:, 'correctedTime'].dt.day\n",
    "phones.loc[:, 'minute'] = phones.loc[:, 'correctedTime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='day', data=phones, hue='parsedSource', )\n",
    "plt.title('Invoca Tweets from Cell Phones by Day of Month');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='1/1/2018', periods=5, tz='Asia/Tokyo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of metadeta accompanies these counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones['entities'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the names of mentioned people and groups by looping over our JSON like any other python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMentions(entities, remove = ['invoca']):\n",
    "    \n",
    "    mentions = entities['user_mentions']\n",
    "    numMentions = len(mentions)\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    for i in range(numMentions):\n",
    "        name = mentions[i]['name'].lower()\n",
    "        \n",
    "        if name not in remove:\n",
    "            names += [name]\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractMentions(phones['entities'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.loc[:, 'mentions'] = phones.loc[:, 'entities'].apply(extractMentions)\n",
    "phones.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sum of a series of lists is just one big list\n",
    "allMentions = phones['mentions'].sum()\n",
    "print phones['mentions'][:3]\n",
    "print\n",
    "print allMentions[:5]\n",
    "\n",
    "# casting the big list as a series allows us to use pandas functionality\n",
    "pdMentions = pd.Series(allMentions)\n",
    "mentionCounts = pdMentions.value_counts()\n",
    "\n",
    "filteredMentions = mentionCounts[mentionCounts > 2]\n",
    "filteredMentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.barplot(x=filteredMentions.index, y=filteredMentions)\n",
    "plt.title('Twitter Mentions for Posts Made from Cell Phones')\n",
    "plt.xticks(rotation = 45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. How we do examine the inherent strata within our dataframe? groupby is great place to start.\n",
    "\n",
    "(documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.groupby(['month']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = phones.groupby(['month']).agg(lambda x: len(x) + np.random.normal(scale=20))\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.groupby('hour')['minute'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.groupby(['month', 'day']).count().loc[[2, 4], :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.groupby(['month', 'day']).count().loc[(2, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.groupby(['month']).agg([np.mean, np.std,lambda x: np.sum(x**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulDF = phones.groupby(['month', 'day']).count().loc[[2, 4], :, :].T\n",
    "usefulDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulDF.to_pickle('savedData.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('savedData.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(lengths.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html\n",
    "for profiling sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"conda install line_profiler\" in your environment to utilize the code profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMention = {u'hashtags': [],\n",
    "                u'symbols': [],\n",
    "               u'urls': [{u'display_url': u'mtech.today/2DsAqjr',\n",
    "               u'expanded_url': u'https://mtech.today/2DsAqjr',\n",
    "               u'indices': [97, 120],\n",
    "               u'url': u'https://t.co/rwauvWY2gy'}],\n",
    "               \n",
    " u'user_mentions': [\n",
    "     \n",
    "      {u'id': 747815998531768324L,\n",
    "       u'id_str': u'747815998531768324',\n",
    "       u'indices': [3, 17],\n",
    "       u'name': u'MarTech Today',\n",
    "       u'screen_name': u'martech_today'},\n",
    "     \n",
    "     \n",
    "      {u'id': 1067019368,\n",
    "       u'id_str': u'1067019368',\n",
    "       u'indices': [83, 96],\n",
    "       u'name': u'Barry Levine',\n",
    "       u'screen_name': u'xBarryLevine'}\n",
    " \n",
    " ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f extractMentions extractMentions(testMention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"conda install memory_profiler\" in your environment to analyze memory usage of imported scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file extractMentions.py\n",
    "def extractMentionsScript(entities, remove = ['invoca']):    \n",
    "    \n",
    "    mentions = entities['user_mentions']\n",
    "    numMentions = len(mentions)\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    for i in range(numMentions):\n",
    "        name = mentions[i]['name'].lower()\n",
    "        \n",
    "        if name not in remove:\n",
    "            names += [name]\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractMentions import extractMentionsScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f extractMentionsScript extractMentionsScript(testMention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
